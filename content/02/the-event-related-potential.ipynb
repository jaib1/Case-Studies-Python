{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "# The Event-Related Potential *for the practicing neuroscientist*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "_**Synopsis**_ \n",
    "\n",
    "**Data:** 1 s of scalp EEG data sampled at 500 Hz during 1,000 trials in two conditions.\n",
    "\n",
    "**Goal:** Characterize the response of the EEG in the two conditions.\n",
    "\n",
    "**Tools:** Visualization, event-related potential, confidence intervals, bootstrapping.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Background](#background)\n",
    "* [Case Study Data](#case-study-data)\n",
    "* [Data Analysis](#data-analysis)\n",
    "    * [Visual Inspection](#visual-inspection)\n",
    "    * [Plotting the ERP](#plotting-the-erp)\n",
    "    * [Confidence Intervals for the ERP (Method 1)](#cis-m1)\n",
    "    * [Comparing ERPs](#comparing-erps)\n",
    "    * [Confidence Intervals for the ERP (Method 2)](#cis-m2)\n",
    "    * [A Bootstrap Test to Compare ERPs](#bootstrap)\n",
    "* [Summary](#summary)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start any computations, let's import some modules and functions that we will use throughout the chapter. A module can be imported any time, but there are a few things that we know we will need straight off the bat. For clarity, it is best practice to import packages at the beginning. \n",
    "\n",
    "You will see that we have imported `matlab.pyplot` and can call any functions in the module with `plt.f()`, where `f` should be replaced with the name of the desired function. Hence, if we want to plot something, with would call `plt.plot()`. However, we will use that function so often that it will be convenient to import `plot()` directly without typing `plt` first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat       # Import function to read data.\n",
    "from IPython.lib.display import YouTubeVideo  # Enable YouTube videos\n",
    "import numpy as np                 # Import numpy for computations\n",
    "import matplotlib.pyplot as plt    # Import a useful plotting package, \n",
    "from matplotlib.pyplot import plot, xlabel, ylabel, title, show, subplots, savefig\n",
    "                                   # ... and a few specific functions that are used often\n",
    "# Tools for this chapter\n",
    "from matplotlib.pyplot import imshow, colorbar, hlines, vlines\n",
    "from numpy import sqrt\n",
    "from numpy.random import randint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On-ramp: computing the event-related potential in Python\n",
    "\n",
    "We begin this module with an \"*on-ramp*\" to analysis. The purpose of this on-ramp is to introduce you immediately to a core concept in this module: how to compute an event-related potential with error bars in Python. You may not understand all aspects of the program here, but that's not the point. Instead, the purpose of this on-ramp is to  illustrate what *can* be done. Our advice is to simply run the code below and see what happens ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display info on the data: \n",
    "data = loadmat('EEG-1.mat') # `loadmat` returns a dict\n",
    "# view the keys\n",
    "print('The keys in `data` are: \\n  ' + str(data.keys()))\n",
    "# There are two sets of EEGs for two conditions: EEGa, and EEGb.\n",
    "# Pull out `EEGa` and `t` from `data`, and view the shape of these variables.\n",
    "eeg_a = data['EEGa']\n",
    "t = data['t'][0]\n",
    "print('The shape of `t` is: ' + str(t.shape))\n",
    "print('The shape of `eeg_a` is: ' + str(eeg_a.shape))\n",
    "# get the number of trials by looking at the number of rows in `eegA`\n",
    "ntrials = len(eeg_a) # this is equivalent to `eegA.shape[0]`\n",
    "print('The number of trials in `eeg_a` is: ' + str(ntrials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ERP:\n",
    "mn_a = eeg_a.mean(0)  # Compute the mean signal across trials for `eegA` (this is the ERP)\n",
    "sd_a = eeg_a.std(0)  # Compute the std of the signal across trials\n",
    "sd_mn_a = sd_a / sqrt(ntrials)  # Compute the std of the mean\n",
    "\n",
    "# Ensure the mean was computed across trials for each time point (not across time for each trial):\n",
    "if (mn_a.size == t.size):\n",
    "    print('The length of the mean of `eeg_a` is ' + str(t.size) + ' timepoints')\n",
    "else:\n",
    "    print('The mean of `eeg_a` was not calculated correctly')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the ERP with 95% confidence intervals:\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12,4)\n",
    "# Plot ERP in default color, and plot upper and lower bounds\n",
    "# for 95% confidence interval in black\n",
    "ax.plot(t, mn_a, lw=3) # ERP\n",
    "ax.plot(t, mn_a + 2 * sd_mn_a, 'k:', lw=1) # Upper confidence interval bound\n",
    "ax.plot(t, mn_a - 2 * sd_mn_a, 'k:', lw=1) # Lower confidence interval bound\n",
    "# Add labels:\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_ylabel('Voltage [$\\mu$ V]')\n",
    "ax.set_title('ERP of condition A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q:** Try to read the code above. Can you see how it loads data, computes the event-related potential and error, and then plots the results?\n",
    "\n",
    "**A:** If you've never computed an event-related potential before, that's an especially difficult question. Please continue on to learn this **and more**!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background <a class=\"anchor\" id=\"background\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('Cy_BF7smAkk')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voltage recordings from the scalp surface - the electroencephalogram or EEG - provide a powerful window into brain voltage activity.  Some of the earliest human EEG recording occurred in 1924, when [Dr. Hans Berger](https://en.wikipedia.org/wiki/Hans_Berger) made a remarkable discovery:  the EEG of a human subject at rest with eyes closed exhibits rhythmic activity, an approximately 10 Hz oscillation he labeled the alpha rhythm.  Although now studied for nearly 100 years, the definitive functional role (if any) of the alpha rhythm remains unknown.  Since then, many other EEG rhythms have been detected and labelled (typically with Greek letters) and the analysis of EEG rhythms remains [an active area of research](https://global.oup.com/academic/product/rhythms-of-the-brain-9780199828234). \n",
    "\n",
    "Compared to other modalities for measuring brain activity, the EEG possesses both advantages and disadvantages.  Perhaps the most important advantages are:\n",
    "\n",
    "1. The EEG is non-invasive, and\n",
    "2. The EEG permits a high temporal resolution (on the order of milliseconds).\n",
    "\n",
    "However, the EEG measure also suffers from significant disadvantages, the most devastating being the poor spatial resolution;  a single scalp electrode detects the summed activity from approximately 10 cm<sup>2</sup> of cortex.\n",
    "\n",
    "In this chapter, we consider EEG data recorded from a single scalp electrode.  We will analyze these data to determine what (if any) activity is evoked following two different types of stimuli presented to a human subject.  In doing so, we will use Python, and see how this powerful tool can help us understand these time series data.  We begin with a brief description of the EEG data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: an EEG ERP task <a class=\"anchor\" id=\"case-study-data\"><a/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('q2-DjvPRaNA')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An undergraduate student volunteers to participate in a psychology study at his university. In this study, EEG electrodes (sampling rate 500 Hz, i.e., 500 samples per second) are placed on the student's scalp, and he is seated in a comfortable chair in a dark, electrically isolated room.  The student is instructed to place headphones over his ears and listen to a series of repeated sounds.  The sounds consist of two tones - either a high pitch tone or a low pitch tone.  A single tone is presented once every few seconds, and the student responds with a button press to the low pitch tone.  The tone presentation is repeated to collect the EEG response to numerous presentations of the two tones, as illustrated here:\n",
    "\n",
    "<img src=\"imgs/2-1.png\">\n",
    "\n",
    "In this cartoon illustration of the EEG experiment, the EEG electrodes are placed on the scalp surface of a human subject (left).  The EEG activity (blue) is recorded as a function of time during presentation of high pitch tones (black) and low pitch tones (orange).\n",
    "\n",
    "Our collaborator leading this research study has agreed to provide us with EEG data recorded at a single electrode for 1000 presentations of the high pitch tone, and 1000 presentations of the low pitch tone.  In each presentation - or \"trial\" - she provides us with 1 s of EEG data, such that the tone occurs at 0.25 s into the trial.  She asks us to analyze these data to determine whether the EEG signal differs following the two tone presentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Inspection <a id=\"visual-inspection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('uSjd41G-yNY')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`eeg_a` is a complicated variable that contains many elements. To understand this data, we might attempt to read the values contained in each element. For example, we can print out the EEG data for the first trial of condition A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eeg_a[0])  # eeg_a[0, :] is equivalent to eeg_a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this command, we index the first row of the matrix `EEGa` and print out all columns (corresponding to all moments of time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "\n",
    "**Q.** Upon issuing this command what do you find? Does the printout help you understand these data?\n",
    "\n",
    "**A.** You should observe a list of 500 numbers that begins \n",
    "\n",
    "    `-1.85909632e-01   4.49876010e-01   1.06070801e+00  -4.71265246e-01   1.68669327e+00   9.38221338e-01 ...`\n",
    "    \n",
    "We might conclude that these numbers exhibit variability (i.e., the values are both positive and negative), but examining the data in this way is not particularly useful. For example, determining trends in the behavior (such as intervals of repeated activity) through inspection of these printed numbers alone is extremely difficult.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('9qx29zDxcAc')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing out the data to the screen is **not useful** in this case. How else can we deepen our understanding of these data? Let’s make a plot:\n",
    "<a id=\"fig:2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(eeg_a[0])                   # Plot the data from condition A, trial 1.\n",
    "# we can save the figure in the 'imgs' folder with a number that matches the textbook, if we want\n",
    "# fig.savefig('imgs/2-2-a.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the data in this way, we immediately notice many features. First, let’s consider the axes. The horizontal axis extends from 0 to (nearly) 500. This corresponds to the 500 columns in the variable `EEGa`. While this visualization is useful, it would be more informative to plot the EEG data as a function of time rather than indices. Fortunately, we possess a variable `t` in the workspace that corresponds to the time axis. Determining the size of the variable `t`, we find it is a vector with 1 row and 500 columns. Each column corresponds to a point in time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** Plot the variable `t`. What is its range? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, eeg_a[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `t` corresponds to the 1 s of EEG data recorded in each trial. We can also use the variable `t` to determine the sampling interval,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick and dirty approach, if we assume `t` is sampled at regular intervals\n",
    "dt = t[1] - t[0]\n",
    "# can also do:\n",
    "dt = np.mean(np.diff(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new variable `dt` corresponds to the time between samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "\n",
    "**Q.** What is the value of `dt`? We were told by our collaborator that the sampling frequency is 500 Hz. Is the value of `dt` consistent with this sampling frequency?\n",
    "\n",
    "**A.** Yes, it is consistent. Using the command `print(dt)`, we find that `dt` is 0.002 s, or 2 ms. The sampling frequency of 500 Hz corresponds to one sample of the EEG data every 1/(500 Hz) = 2 ms. If the two were not consistent, we would return to our collaborator and figure out what has gone wrong. In general, it’s useful to ask such questions along the way to make sure we understand the formatting of the data and catch any potentially serious misunderstandings early in the analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"singleTrial\">\n",
    "    \n",
    "We can now combine the time axis with the EEG data to make a more complete plot. Let’s also label the axes and give the plot a title.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, eeg_a[0], figure=fig) \n",
    "ax.set_xlabel('Time [s]')                   \n",
    "ax.set_ylabel('Voltage [$\\mu$ V]')         \n",
    "ax.set_title('EEG data from condition A, Trial 1')\n",
    "\n",
    "# Add a vertical line to indicate the stimulus onset time\n",
    "stim_onset_time = 0.25\n",
    "max_abs_V = np.max(np.abs(eeg_a))\n",
    "ax.vlines(stim_onset_time, -max_abs_V, max_abs_V, 'r', lw=2)\n",
    "# we can save the figure in the 'imgs' folder with a number that matches the textbook, if we want\n",
    "# fig.savefig('imgs/2-2-c.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot provides a nice summary of the data in the first trial of condition A. Visual inspection of the plot suggests that these data exhibit complicated activity. We know from our collaborator that the stimulus occurs at time 0.25 s in each trial. Note how we indicated this time as a vertical line in the plot above. This command includes additional options that make the line red (`'red'`) and a bit wider (`lw=2`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** What else, if anything, can you say about the single trial of EEG data plotted above? Does the visual inspection reveal any particular change in the EEG activity following the stimulus presentation?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have visualized only the data from condition A. Because we are interested in whether the EEG behaves differently in the two conditions, visualizing both conditions simultaneously would be of use. We can do this as follows:\n",
    "<a id=\"fig:3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a wider figure, and plot the first trial from both eeg_a and eeg_b:\n",
    "eeg_b = eeg_b = data['EEGb']\n",
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "ax.plot(t, eeg_a[0])           \n",
    "ax.plot(t, eeg_b[0])\n",
    "\n",
    "# Add labels:\n",
    "ax.set_xlabel('Time [s]')             \n",
    "ax.set_ylabel('Voltage [\\mu V]')       \n",
    "ax.set_title('EEG data across conditions, Trial 1')\n",
    "ax.legend(['eeg_a', 'eeg_b'])\n",
    "\n",
    "# we can save the figure in the 'imgs' folder with a number that matches the textbook, if we want\n",
    "# fig.savefig('imgs/2-3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** Compare the voltage traces from the first trial of conditions A and B as plotted above. What similarities and differences do you observe?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A__: Hard to see any particular differences here besides the fact that eeg_b has greater absolute amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** The analysis has so far focused only on the first trial. Repeat this visual inspection of the data for different trials. What do you find? What similarities and differences exist between the two conditions across trials?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot of the next 10 trials\n",
    "fig, ax = plt.subplots(5,2, figsize=(12,15))\n",
    "fig.set_tight_layout(True) # make sure there's no unnecessary overlap or whitespace between axes \n",
    "\n",
    "for trial in range(1,11):\n",
    "    # Get the appropriate row, `r`, and column, `c` of the\n",
    "    # subplot to plot to, depending on the current trial number.\n",
    "    if np.mod(trial,2):\n",
    "        r = int((trial-1)/2)\n",
    "        c = 0\n",
    "    else:\n",
    "        r = int((trial/2)-1)\n",
    "        c = 1\n",
    "    \n",
    "    # Plot the data and set labels.\n",
    "    ax[r][c].plot(t, eeg_a[trial])\n",
    "    ax[r][c].plot(t, eeg_b[trial])\n",
    "    ax[r][c].set_title('EEG data, trial ' + str(trial))\n",
    "    ax[r][c].legend(['eeg_a', 'eeg_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('nandZ5aaRaQ')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These techniques allow us to visualize the data one trial at a time. That is useful but can be time consuming, especially for a large number of trials. For the EEG data of interest here, each condition contains 1,000 trials, and to visualize each trial separately could require 2,000 plots. We can certainly create 2,000 plots, but the subsequent visual inspection would be time consuming and difficult. Fortunately, a more efficient visualization approach exists: we can display the entire structure of the data across both time and trials as an image:\n",
    "<a id=\"fig:4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# Plot all trials of `eeg_a` and `eeg_b` in a colormap:\n",
    "fig, ax = plt.subplots(2,1, figsize=(12,6))\n",
    "fig.set_tight_layout(True)\n",
    "ax[0].imshow(eeg_a,\n",
    "           extent=[t[0], t[-1], 0, ntrials], # specify axes lims      \n",
    "           aspect='auto') # specify aspect ratio\n",
    "c_bar_map = ax[1].imshow(eeg_b,\n",
    "           extent=[t[0], t[-1], 0, ntrials],       \n",
    "           aspect='auto')\n",
    "# We want to use one set of common labels for both axes.\n",
    "# To do this, create one big, hidden subplot, and give\n",
    "# this subplot labels. \n",
    "hid_ax = fig.add_subplot(1,1,1, frameon=False)\n",
    "hid_ax.tick_params(labelcolor='none', length = 0)\n",
    "hid_ax.set_ylabel('Trial #')\n",
    "hid_ax.set_ylabel('Time (s)')\n",
    "\n",
    "# Decrease tick labels of `ax` so they don't interfere with\n",
    "# labels of `hid_ax`\n",
    "ax[0].tick_params(labelsize='x-small') # this can be string or numeric\n",
    "ax[1].tick_params(labelsize='x-small')\n",
    "\n",
    "# Add a colorbar to a separate axes on the figure\n",
    "divider_hid_ax = make_axes_locatable(hid_ax)\n",
    "divider_ax0 = make_axes_locatable(ax[0])\n",
    "divider_ax1 = make_axes_locatable(ax[1])\n",
    "hid_ax0 = divider_ax0.append_axes('right', size='5%', pad='5%')\n",
    "hid_ax1 = divider_ax1.append_axes('right', size='5%', pad='5%')\n",
    "hid_ax0.set_visible(False)\n",
    "hid_ax1.set_visible(False)\n",
    "cax = divider_hid_ax.append_axes('right', size='5%', pad='5%')\n",
    "cbar = fig.colorbar(c_bar_map, cax=cax) # Show voltage to color mapping\n",
    "cbar.set_label('Voltage ($\\mu$ V)', rotation=-90)\n",
    "\n",
    "# Add lines for stimulus onset times\n",
    "ax[0].vlines(stim_onset_time, 0, ntrials, 'r', lw=2, label='stim onset time')\n",
    "ax[1].vlines(stim_onset_time, 0, ntrials, 'r', lw=2)\n",
    "ax[0].legend()\n",
    "\n",
    "# we can save the figure in the 'imgs' folder with a number that matches the textbook, if we want\n",
    "# fig.savefig('imgs/2-4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `imshow` command allows us to visualize the entire matrix `EEGa` as a function of trial number and time. Each row corresponds to a single trial of duration 1 s, and the color indicates the voltage, with darker (lighter) colors indicating higher (lower) voltages. This plot also indicates the time of stimulus presentation with a vertical black line as a cue to assist visual inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"python-note\">\n",
    "    \n",
    "We have used the *BuPu* color map for the plot above. There are many other options; use `plt.colormaps?` for details.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.**\n",
    "Upon close inspection of the figure above, what response, if any, do you observe following the stimulus presentation? (Look *really* carefully.) Repeat this visualization and analysis for `EEGb`. How do the two conditions compare?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the ERP <a id=\"plotting-the-erp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('kPr2GLSKLJg')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection of the EEG data has so far come up empty. The EEG traces appear noisy or perhaps rhythmic, but from visual inspection of the individual trials it’s difficult to make a decisive conclusion of underlying structure (<a href=\"#singleTrial\">see above</a>). To further investigate the activity in these data, we compute the **event-related potential** (ERP).\n",
    "\n",
    "To compute the ERP, we first assume that each trial evokes an instantiation of the same underlying brain process. So, in this case, we assume that the same brain response is evoked 1,000 times (once for each trial) for each condition. However, the evoked response due to the stimulus is small and hidden in the EEG signal by other ongoing activity unrelated to the stimulus (e.g., daydreaming, thoughts of dinner, thoughts of homework). Therefore, to tease out the weak evoked effect, **we average the EEG responses across trials**. Ideally, EEG activity unrelated to the stimulus will cancel out in the average, while EEG activity evoked by the stimulus will sum constructively. The procedure to perform and display this averaging can be done in Python as follows:\n",
    "<a id=\"fig:5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(t, EEGa.mean(0))  # Plot the ERP of condition A\n",
    "xlabel('Time [s]')           # Label the axes\n",
    "ylabel('Voltage [$\\mu V$]')\n",
    "title('ERP of condition A')  # ... provide a title\n",
    "savefig('imgs/2-5')\n",
    "show()                       # ... and show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first line, we compute the mean of `EEGa` using the method `mean()`; see the documentation for this function [here](https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html). The default behavior is to compute the mean of all elements of the array. By calling `EEG.mean(0)`, we compute the mean along the zeroth dimension. The result is the ERP for condition A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** Consider the ERP for condition A plotted above. Update this figure to include a vertical line at the location of the stimulus, and the ERP for condition B. How, if at all, do the ERPs for Conditions A and B differ?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ERP of condition A shows the mean voltage across trials at each moment in time. Visual inspection suggests that before stimulus presentation (i.e., times 0 s to 0.25 s) the EEG fluctuates around zero. Then, after stimulus presentation, the ERP increases and decreases substantially above and below zero. Which, if any, of these deviations following stimulation are significant? To address this, we make use of the trial structure of the EEG data to compute confidence bounds for the ERP. We do so in two ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals for the ERP (Method 1) <a id=\"cis-m1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('pXCJbyrw8Ug')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the ERP we average the EEG data across many trials. Because of this, we may make use of a powerful theorem in statistics—the [*central limit theorem*](https://en.wikipedia.org/wiki/Central_limit_theorem) (CLT)—to include approximate confidence bounds in the ERP figure. Briefly, this theorem states that the mean of a sufficiently large number of independent random variables, each with finite mean and variance, will be approximately [normally distributed](https://en.wikipedia.org/wiki/Normal_distribution). Remember that the ERP at each moment in time is the sum of EEG activity across trials (then scaled by a constant, the number of trials). Let’s assume that the trials are independent (i.e., one trial does not depend on any other trial). Let’s also assume that the EEG data at each moment in time have finite mean and variance. With those assumptions, we have satisfied the CLT and may therefore conclude that the ERP at each moment in time is approximately normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** To use the CLT, we make two assumptions about the EEG data. Are these assumptions reasonable?\n",
    "\n",
    "**A.** We assume that the EEG data are independent across trials. This assumption may fail if, for example, the activity in one trial influences the activity in the next trial. We also assume that the EEG data are “well-behaved” (i.e., have finite mean and variance). That is a reasonable assumption for physical data we observe from the brain; we expect the EEG data to always remain finite and not diverge to plus or minus infinity.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This conclusion—that the ERP at each moment in time is approximately normally distributed—is useful because the normal distribution (also known as the Gaussian distribution or bell curve) possesses many convenient properties. First, a normal distribution is relatively simple; it can be completely specified with two parameters: the mean value and the standard deviation. Second, 95% of the values drawn from a normal distribution lie within approximately two standard deviations of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/gaussian.png\" alt=\"Example Gaussian\" style=\"width:40%; max-width:300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a plot of the canonical normal distribution showing the mean (dotted vertical line) and standard deviation (blue). Ninety-five percent of values lie within the interval indicated by the red bar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, to construct a 95% confidence interval for the ERP, we need to determine the mean and standard deviation of the mean across trials at each point in time. To compute the mean in Python is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = EEGa.mean(0)  # Compute the mean across trials (the ERP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"python-note\">\n",
    "    \n",
    "Note that when we refer to the *mean* here we could instead write *sample mean* because we use the observed data to estimate the theoretical mean that we would see if we kept repeating this experiment. This distinction is not essential to our goals here, but it is important when talking to your statistics-minded colleagues. Throughout the book, we omit the term sample when referring to sample means, variances, covariances, and so forth, unless this distinction is essential to the discussion.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again note that the second input to the `mean` function specifies the dimension in which we compute the mean, in this case, across the first dimension of the variable `EEGa` corresponding to the trials. To compute the standard deviation of the mean, we start by computing the standard deviation of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = EEGa.std(0)  # Compute the std across trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we’re not interested in the standard deviation of the EEG data across trials; instead, we’re interested in the standard deviation *of the estimate of the mean*. To calculate the standard deviation of the mean, we divide the standard deviation of the data by the square root of the number of trials (i.e., the number of terms used to compute the mean). In Python,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdmn = sd / sqrt(ntrials)  # Compute the std of the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, having found the mean (`mn`) and the standard deviation of the mean (`sdmn`), we can compute a 95% confidence interval for the ERP. We again exploit the observation, based on the central limit theorem, that the ERP is normally distributed at each instant of time. With these calculations, the following code plots the ERP and the 95% confidence interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = subplots(figsize=(12, 3))     # Save the axes for use in later cells and resize the figure\n",
    "ax.plot(t, mn, 'k', lw=3)              # Plot the ERP of condition A\n",
    "ax.plot(t, mn + 2 * sdmn, 'k:', lw=1)  # ... and include the upper CI\n",
    "ax.plot(t, mn - 2 * sdmn, 'k:', lw=1)  # ... and the lower CI\n",
    "xlabel('Time [s]')                     # Label the axes\n",
    "ylabel('Voltage [$\\mu$ V]')\n",
    "title('ERP of condition A')            # ... provide a useful title\n",
    "fig                                    # ... and show the plot\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ERP computed with confidence intervals allows us to ask specific questions about the data. For example, does the ERP ever differ significantly from zero? To answer this, we look for intervals of the ERP for which the confidence intervals do not include zero. To aid visual inspection, we add to the ERP plot a horizontal line at 0: <a id=\"plt:erpA-m1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"python-note\">\n",
    "    \n",
    "A good rule of thumb when you are programming is that you should not be rewriting (or copy-pasting) code over and over again. Instead, you should write a function that you can call whenever you need the action that you keep repeating. At this point, we have resized the plots and labeled the axes the same way several times so we should fix the default plot size and write a function that automates the labeling so that next time we make a plot, we don't need to rewrite the same code again.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the default figure size\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 3)\n",
    "\n",
    "# Create a function to label plots\n",
    "def labelPlot(title_string=\"Title\"):\n",
    "    '''\n",
    "    A function that labels the x-axis as 'Time [s]' and\n",
    "    the y-axis as 'Voltage [$\\mu V$]'. \n",
    "    Arguments:\n",
    "        title_string:  string variable to be used as\n",
    "                       the plot title (default: 'Title')\n",
    "                       \n",
    "    '''\n",
    "    xlabel('Time [s]')           # x-axis is time\n",
    "    ylabel('Voltage [$/mu V$]')  # y-axis is voltage\n",
    "    title(title_string)          # use the input here\n",
    "    plt.autoscale(tight=True)    # no white-space in plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** How would you write a function to compute the ERP and confidence bounds of a dataset?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** What do you think the following code will do?\n",
    "\n",
    "    ax.hlines(0, t[0], t[-1])\n",
    "\n",
    "Try it out.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** What is the role of the method function `hlines()` in this code? *Hint*: If you have not encountered this function before, look it up in the Documentation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hlines(0, t[0], t[-1])\n",
    "fig.savefig('imgs/2-7')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure above, the thick line indicates the ERP for Condition A (i.e., the mean of the EEG across trials) while the thin dotted lines indicate the 95% confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find three time intervals at which the confidence intervals of the ERP do not include zero: near 0.27 s, near 0.37 s, and near 0.47 s. These results suggest that for an interval of time following the stimulus presentation in condition A, the observed ERP is not a random fluctuation about zero but instead contains consistent structure across trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** Construct the ERP with confidence intervals for condition B. As for condition A, you should find that before stimulus presentation the ERP fluctuates around zero. What intervals of time, if any, differ significantly from zero?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing ERPs <a class=\"anchor\" id=\"comparing-erps\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we implemented a procedure to compute confidence intervals for the ERPs in conditions A and B. To investigate *differences* between the ERPs in the two conditions, we can use a similar approach. To start, let’s plot the ERPs with confidence intervals for both conditions and attempt to identify periods for which the confidence intervals do not overlap (such intervals would correspond to significant differences between the responses of the two conditions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_module import ERP  # A function written by the author to compute the ERP\n",
    "\n",
    "erpA, ca_l, ca_h = ERP(data['EEGa'])  # Compute the ERP of condition A\n",
    "erpB, cb_l, cb_h = ERP(data['EEGb'])  # ... and condition B\n",
    "\n",
    "plot(t, ca_l, 'r:', t, ca_h, 'r:')  # Plot confidence bounds in back\n",
    "plot(t, cb_l, 'b:', t, cb_h, 'b:')\n",
    "plot(t, erpA, 'r', lw=3, label='condition A')  # ... and ERPs in front\n",
    "plot(t, erpB, 'b', lw=3, label='condition B')\n",
    "\n",
    "# Prettify\n",
    "labelPlot('ERP of conditions A and B')\n",
    "legend()\n",
    "savefig('imgs/2-8a')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** In the cell above, the ERPs and confidence bounds are computed using a function written by the author. Can you write the code to make this plot yourself?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the plot of both ERPs is rather messy; it’s difficult to determine through visual inspection alone in which intervals the ERPs exhibit significant separation.\n",
    "\n",
    "To facilitate further inspection of the data, we compute the difference between the ERPs in the two conditions. In the differenced signal, large deviations between the two conditions will appear as large differences from zero. To determine whether a deviation is significantly different from zero, we need to determine the confidence interval for the differenced ERP. This requires we propagate the standard deviation of the mean for both ERPs to the new differenced ERP. The propagated standard deviation of the mean at a fixed moment in time is computed as,\n",
    "\n",
    "<a id=\"eq:1\"></a>\n",
    "$$ \\sigma = \\sqrt{\\frac{\\sigma_A^2}{K} + \\frac{\\sigma_B^2}{K}}, \\tag{1}$$\n",
    "\n",
    "where $\\sigma_A$ is the standard deviation of the data from condition A, $\\sigma_B$ is the standard deviation of the data from condition B, and $K$ is the number of trials. In Python we compute the differenced ERP and standard deviation of the mean of the difference as follows:\n",
    "<a id=\"plt:differencedERP\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnA = EEGa.mean(0)  # ERP of condition A\n",
    "sdmnA = EEGa.std(0) / sqrt(ntrials)  # ... and standard dev of mean\n",
    "\n",
    "mnB = EEGb.mean(0)  # ERP of condition B\n",
    "sdmnB = EEGb.std(0) / sqrt(ntrials)  # ... and standard dev of mean\n",
    "\n",
    "mnD = mnA - mnB  # the differenced ERP\n",
    "sdmnD = sqrt(sdmnA ** 2 + sdmnB ** 2)  # ... and its standard dev\n",
    "\n",
    "plot(t, mnD, 'k', lw=3)  # plot the differenced ERP\n",
    "plot(t, mnD + 2 * sdmnD, 'k:')  # ... the upper CI\n",
    "plot(t, mnD - 2 * sdmnD, 'k:')  # ... and the lower CI\n",
    "plot([0, 1], [0, 0], 'b')  # ... and a horizontal line at 0\n",
    "labelPlot('Differenced ERP')  # label the plot\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above we first compute the ERP and standard deviation of the mean for each condition. We then compute the differenced ERP (`mnD`) and the standard deviation of the mean of this difference (`sdmnD`) using equation (<a href=\"#eq:1\" class=\"thumb\">1<span><img src=\"imgs/eq1.png\"></span></a>). We note that `sdmnA` $ = \\sqrt{\\sigma_A^2/K}$ and therefore `sdmnA**2` $= \\sigma_A^2/K$, with similar expressions for condition B. We then plotted the resulting differenced ERP with 95% confidence intervals. The hope is that from this figure we can more easily identify significant differences between the two conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q:** Examine the plot of the differenced ERP. In what intervals of time do the EEG responses in the two conditions significantly differ?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals for the ERP (Method 2) <a id=\"cis-m2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('vVXH4XsPFEs')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have computed confidence intervals for the ERPs by relying on the central limit theorem and approximating the average voltage values at each point in time as normally distributed. That’s a completely reasonable approach. And because the normal distribution is so well-behaved, it’s easy to compute the 95% confidence intervals. An alternative approach to generate confidence intervals is through a **bootstrap** procedure. Bootstrapping is a resampling method that allows us to estimate the sampling distribution of many different statistics. In this chapter, we implement a *nonparametric bootstrap* (see note). To do so, we generate new *pseudodata* from the observed EEG data. We begin by using a bootstrapping procedure to create confidence intervals for the ERPs observed in each condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"math-note\">\n",
    "    \n",
    "**A note on the nonparametric bootstrap.** Briefly, there is strong theoretical justification for the nonparametric bootstrap. The fundamental idea is that resampling the data with replacement is equivalent to sampling new pseudodata from the empirical cumulative distribution function (eCDF) of the observed data. For a large sample of independent, identically distributed random variables, the distribution of the pseudodata generated from the eCDF will be close to the true distribution of the data. Note the important caveat that the variables are independent, identically distributed; this assumption fails in many cases, such as for time series. Here, we assume that each trial is drawn independently from the same distribution (i.e., the trials are independent, identically distributed variables).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the bootstrapping procedure to compute pointwise confidence intervals. By pointwise we mean that the confidence intervals are computed separately for each point in time, and interactions across time are not considered. The prescription for the bootstrapping procedure follows four steps:\n",
    "\n",
    "1. Sample with replacement 1,000 trials of the EEG data from condition A.\n",
    "1. Average these 1,000 trials to create a resampled ERP.\n",
    "1. Repeat these two steps 3,000 times to create a distribution of ERPs.\n",
    "1. For each time point, identify the values greater than 2.5% and less than 97.5% of all 3,000 values. This range determines the 95% confidence interval for the ERP for that time point.\n",
    "\n",
    "Let’s now implement each step in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('mqDEJyW_z4c')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.** In step 1 we must sample with replacement from the EEG data. To visualize this procedure, imagine placing 1,000 marbles in an opaque bag. Each marble is assigned a unique integer value from 1 to 1,000. Now, reach your hand into the bag, grab a marble, record its number, and replace the marble in the bag. We assume that each marble is equally likely to be selected at each draw (i.e., there are no special features that allow some marbles to be drawn more often). Repeat this procedure 1,000 times to create a list of 1,000 integers. Notice that after recording the drawn marble’s number, we replace it in the bag. So, we could potentially draw the same marble 1,000 times, although that’s extremely unlikely. Performing this sampling with replacement procedure by hand would, of course, be extremely time consuming (e.g., who will paint integers on each marble?). Fortunately, Python provides a function to perform sampling with replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw 1000 integers with replacement from [0, 1000)\n",
    "i = np.random.randint(0, ntrials, size=ntrials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and second inputs to `randint()` specify the minimum and maximum integers to draw, respectively. Note that the low number is included in the set, but the high number is not. If only the upper bound is given, the lower bound is assumed to be zero (i.e., we can rewrite the above line as `np.random.randint(ntrials, size=ntrials)`). The last input indicats the number of samples to draw (as always, use `np.random.randint?` to find out more)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** Examine the values of `i`. What values do you find?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result `i` provides a list of integers between 0 and 999. These values specify the trials to use in creating the resampled EEG. This resampled EEG will contain the same number of trials as the original EEG (i.e., 1,000 trials) but in a different order and with possibly repeated trials. For example, if the sampling with replacement procedure returns\n",
    "\n",
    "    i = [10, 941, 3, 400, 10, ...\n",
    "\n",
    "then the first and fifth trials of the resampled EEG will equal the tenth trial of the original EEG. We create the resampled EEG in Python as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG0 = EEGa[i]  # Create the resampled EEG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code we use the variable `i` as the index to the rows of `EEGa`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** What is the `shape` of the new variable `EEG0`? Is this shape consistent with the original EEG datasets?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That completes step 1 of the resampling procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('bUzuNojLUik')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.** This step is easy: we create a resampled ERP from the resampled EEG data. Computing the resampled ERP requires only one line of code in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERP0 = EEG0.mean(0)  # Create the resampled ERP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** What is the difference between the resampled EEG and resampled ERP? Explain your answer in words.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** Plot the resampled ERP that we created. What does it look like?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('feQk_vKloXk')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.** In the first two steps of the resampling procedure we created a single resampled ERP. In step 3 we are instructed to repeat this procedure 3,000 times and create a distribution of ERPs. How can we do so? One potential solution is to cut and paste the code we developed over and over again, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(ntrials, size=ntrials);  # Draw integers,\n",
    "EEG1 = EEGa[i];  # ... create resampled EEG,\n",
    "ERP1 = EEG1.mean(0);  # ... create resampled ERP.\n",
    "\n",
    "i = np.random.randint(ntrials, size=ntrials);  # Draw integers,\n",
    "EEG2 = EEGa[i];  # ... create resampled EEG,\n",
    "ERP2 = EEG2.mean(0);  # ... create resampled ERP.\n",
    "\n",
    "i = np.random.randint(ntrials, size=ntrials);  # Draw integers,\n",
    "EEG3 = EEGa[i];  # ... create resampled EEG,\n",
    "ERP3 = EEG3.mean(0);  # ... create resampled ERP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these lines we have created three resampled ERPs, each with its own variable name. We could, of course, repeat this procedure and eventually define the variable `ERP3000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** Is defining the resampled ERPs in this way a good idea?\n",
    "\n",
    "**A.** No! We should let the computer execute this repeated procedure for us. If you find yourself cutting and pasting the same code over and over again, you're probably doing something inefficient, inelegant, and error-prone.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better approach to create the 3,000 resampled ERPs is with a *for-loop*. We do so in Python with the `for` statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapERP(EEGdata, size=None):  # Steps 1-2\n",
    "    \"\"\" Calculate bootstrap ERP from data (array type)\"\"\"\n",
    "    ntrials = len(EEGdata)  # Get the number of trials\n",
    "    if size == None:  # Unless the size is specified,\n",
    "        size = ntrials  # ... choose ntrials\n",
    "    i = np.random.randint(ntrials, size=size)  # ... draw random trials,\n",
    "    EEG0 = EEGdata[i]  # ... create resampled EEG,\n",
    "    return EEG0.mean(0)  # ... return resampled ERP.\n",
    "\n",
    "ERP0 = [bootstrapERP(EEGa) for _ in range(3000)]  # Step 3: Repeat 3000 times \n",
    "ERP0 = np.array(ERP0)  # ... and convert the result to an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first line, we define a function that performs the calculations that we wish to repeat. In this case, the function performs steps 1 and 2 of the bootstrapping procedure. The last two lines call the function 3,000 times and convert the result from a *list* into an *array*. This completes step 3 of the bootstrapping procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"python-note\">\n",
    "    \n",
    "Note that in the definition of `bootstrapERP`, we included an argument (`size`) that has a *default* value (`None`). This lets us assume that we want the resampled dataset to be the same size as the original, which is true for right now. Later, however, we will reuse this function but will not want the resampled data to be the same size as the original.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"python-note\">\n",
    "    \n",
    "In Python it is common to see for-loops written in the form\n",
    "\n",
    "    y = [f(x) for x in some_set]\n",
    "\n",
    "This will return a *list* datatype, which is why we had to convert it to an array in the code above. We could also have written the loop in an alternative way:\n",
    "\n",
    "    ERP0 = np.zeros((3000, EEGa.shape[1]))\n",
    "    for k in range(3000):\n",
    "        ERP0[k, :] = bootstrapERP()\n",
    "\n",
    "Note that it is good practice, but not required, to define a function that contains the code you wish to repeat, especially if you might use it again later. This minimizes rewrites, and if there is a mistake then you only need to make a correction in one place.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('NLc93QESVZs')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4.** In this step of the bootstrapping procedure, we determine for each time point the values greater than 2.5% and less than 97.5% of all values. There are many ways to perform this operation in Python, perhaps the easiest being to sort from smallest to largest the 3,000 resampled ERP values at each time point. With the resampled values sorted in this way, we then find the resampled ERP value at index 0.025 $\\times$ 3000 = 75 and 0.975 $\\times$ 3000 = 2925. These indices correspond to the resampled ERP values greater than 2.5% of all values and greater than 97.5% of all values, respectively, and therefore define the lower and upper confidence intervals at each moment in time. We can compute both confidence intervals in Python, and (at last!) plot the ERP for condition A with confidence intervals computed using the bootstrapping procedure: <a id=\"fig:1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERP0.sort(axis=0)  # Sort each column of the resampled ERP\n",
    "N = len(ERP0)  # Define the number of samples\n",
    "ciL = ERP0[int(0.025*N)]  # Determine the lower CI\n",
    "ciU = ERP0[int(0.975*N)]  # ... and the upper CI\n",
    "mnA = EEGa.mean(0)  # Determine the ERP for condition A\n",
    "plot(t, mnA, 'k', lw=3)  # ... and plot it\n",
    "plot(t, ciL, 'k:')  # ... and plot the lower CI\n",
    "plot(t, ciU, 'k:')  # ... and the upper CI\n",
    "hlines(0, 0, 1, 'b')  # plot a horizontal line at 0\n",
    "                      # ... and label the axes\n",
    "labelPlot('ERP of condition A with bootstrap confidence intervals')  # We define this function above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these results to identify, for example, intervals in which the ERP differs significantly from zero by finding periods in which the confidence intervals do not include zero. The advantage of the bootstrapping procedure over other approaches is that this procedure requires few assumptions about the distribution of the statistic of interest, and that we use the observed data to probe the distribution of the statistic. The disadvantage of the bootstrapping procedure is that it is computationally intensive. Here we considered 3,000 resamplings, but we could easily consider more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** Compare the confidence intervals in the plot above (bootstrap confidence intervals) to [the CLT confidence intervals](#plt:erpA-m1) computed earlier. How are the two results similar or different? What happens to the confidence intervals if you change the number of resamplings in step 3 from 3,000 to 10,000.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** Compute the confidence intervals using the bootstrapping procedure for the ERP of condition B. What do you find?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Bootstrap Test to Compare ERPs <a id=\"bootstrap\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('K6pgCxFdELc')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrapping procedure provides a powerful technique to construct confidence intervals for the ERPs using only the observed EEG measurements. We can apply a similar technique to search for significant differences between the ERPs in conditions A and B. To do so, we first choose a *statistic*, a measure of some attribute of the difference between the two ERPs. There are many choices, some informative and some not. Let’s choose as our statistic the maximum absolute value of the difference in the ERPs across time. Computing this statistic is straightforward in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbA = np.mean(EEGa,0)          # Determine ERP for condition A\n",
    "mnB = np.mean(EEGb,0)          # Determine ERP for condition B\n",
    "mnD = mnA - mnB                # Compute the differenced ERP\n",
    "stat = max(np.abs(mnD))        # Compute the statistic\n",
    "print('stat = {:.4f}'.format(stat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** Given the value we determined for `stat`, are the ERPs for the two conditions different?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('390ywma7S3U')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In isolation, the numerical value for `stat` is not very useful or interesting. Is the value for `stat` consistent with noisy scalp EEG data lacking an evoked response? Or is the value for `stat` large and unexpected to occur unless the ERPs in the two conditions are different? To make the statistic useful, we need `stat` to be interpretable, which we pursue here through a bootstrapping procedure. We assume that no difference exists between the two conditions; in the language of statistics, this is called the [*null hypothesis*](https://en.wikipedia.org/wiki/Null_hypothesis). If the null hypothesis holds, then we can pool all the EEG signals together from both conditions (for a total of 2,000 trials) and draw from this combined distribution to create resampled ERPs representative of either condition.\n",
    "\n",
    "It may seem odd to create pseudodata by selecting trials across both conditions; intuitively, we may expect the data to differ in these two conditions and feel uncomfortable making a pseudodata set that includes trials from both conditions. But under the null hypothesis, we assume no difference between the EEG responses in conditions A and B, and we are therefore free to create pseudodata drawing from trials in both conditions. We do so with the goal of creating a distribution of values for `stat` under the null hypothesis that conditions A and B exhibit no difference. We then compare the observed value of `stat` with this distribution of `stat` values. If there is a difference between the two conditions, we expect to find the observed value of `stat` to be very different from the distribution of `stat` values generated from the pseudodata under the null hypothesis.\n",
    "\n",
    "To create the distribution of `stat` values under the null hypothesis of no difference between the two conditions, we perform a bootstrap test. The idea is similar to the bootstrapping procedure used to construct the [confidence intervals for the ERP](#fig:1) <abbr class=\"figsup\">fig<img src=\"imgs/2-1.png\"></abbr>. We proceed as follows:\n",
    "\n",
    "1. Merge the 1,000 trials each of EEG data from conditions A and B to form a combined distribution of 2,000 trials.\n",
    "1. Sample with replacement 1,000 trials of EEG data from the combined distribution, and compute the resampled ERP.\n",
    "1. Repeat step 2 and compute a second resampled ERP.\n",
    "1. Compute the statistic, the maximum absolute value of the difference between the two resampled ERPs.\n",
    "1. Repeat steps 2-4, 3,000 times to create a distribution of statistic values.\n",
    "1. Compare the observed statistic to this distribution of statistic values. If the observed statistic is greater than 95% of the bootstrapped values, then reject the null hypothesis that the two conditions are the same.\n",
    "\n",
    "The code to implement this procedure is similar to the bootstrapping procedure that we have already implemented to compute the confidence intervals for the ERP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = np.vstack((EEGa, EEGb))  # Step 1. Merge EEG data from all trials\n",
    "np.random.seed(123)  # For reproducibility\n",
    "\n",
    "def bootstrapStat(EEG):  # Steps 2-4.\n",
    "    mnA = bootstrapERP(EEG, size=ntrials)  # Create resampled ERPa. The function 'bootstrapERP' is defined above!\n",
    "    mnB = bootstrapERP(EEG, size=ntrials)  # Create resampled ERPb\n",
    "    mnD = mnA - mnB  # Compute differenced ERP\n",
    "    return max(abs(mnD))  # Return the statistic\n",
    "\n",
    "statD = [bootstrapStat(EEG) for _ in range(3000)]  # Resample 3,000 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we first combine `EEGa` and `EEGb` in a new variable `EEG`.\n",
    "Then, as before, we define the function `bootstrapStat` which performs the operations that we wish to repeat. Both of the first two lines of the function call `bootstrapERP`, the function that we defined earlier to compute a resampled ERP. Note that in this case, we call `bootstrapERP` with `size=ntrials`. When we combined the original datasets in `EEG`, we generated a dataset with twice the number of trials, but we still wish to perform the bootstrap procedure to create a resampled ERP using the original number of trials (1,000). The last two lines of the function compute the resampled difference and return the statistic. Finally, we repeat the procedure 3,000 times using a for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('iefCPGHd5vY')\n",
    "# NO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img alt=\"Bootstrap distribution of statistic values\" title=\"\" src=\"imgs/bootstrapERPdiff.png\" height=\"20\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows the distribution of values for the test statistic under the null hypothesis of no difference between the two conditions. The orange line indicates observed statistic from the EEG data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"python-note\">\n",
    "    \n",
    "The `seed()` function controls the random numbers that are generated. This ensures that when you recreate the plot above, yours will look identical. Nonetheless, if you remove (or comment out) this statement, your plot should still look very similar as the distribution should change only slightly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** See if you can write code to generate this plot using the `hist()` function from the NumPy module. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"question\">\n",
    "    \n",
    "**Q.** Given the distribution of `statD` values shown above, and the value of `stat` computed from the original data, can we conclude that the difference between the two conditions is significant with this statistic?\n",
    "\n",
    "**A.** Yes. Under the null hypothesis, the distribution fo the statistic ranges from approximately 0.15 to 0.33. The observed statistic `stat = 0.2884` exceeds most values in this distribution. Computing `sum(statD > stat)` we find in this example that only 18 of the 3,000 values in the distribution exceed the observed statistic. This corresponds to a proportion of 18/3000 = 0.006. We therefore reject the null hypothesis of no difference between the ERPs of conditions A and B. This result may be surprising, given how similar the two ERPs appear and the large variability in their differences ([see figure](#plt:differencedERP)).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result illustrates the power of the bootstrapping procedure. We proposed a complicated statistic (the maximum absolute value of the difference between the two resampled ERPs). For this statistic, we do not possess an obvious formula to decide whether the resulting statistic is significant (we cannot rely on the CLT, for example). To determine significance, we employ a bootstrapping procedure (also known as a permutation test), which we can perform even for the relatively complicated statistic. In this way, we may devise complicated measures of data and construct error bars or compute statistical significance, provided our computational resources are sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary <a id=\"summary\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we considered scalp EEG data recorded from a single electrode during an auditory task. The task consisted of two conditions, and we sought to uncover the difference in the EEG responses between the two conditions. We began with a visual inspection of the EEG recordings from individual trials and from all trials, and concluded that the data were quite noisy; any evoked response due to the stimulus was not obvious in the single-trial data.\n",
    "\n",
    "To emphasize the evoked signal, we computed the ERP, which involved averaging the EEG signal across trials. By doing so, we uncovered interesting structure in condition A, but not much in condition B. We then developed two techniques to add error bars to an ERP. One technique relied on the central limit theorem, and the other technique involved a computationally expensive bootstrapping procedure. Both techniques suggested that the ERP in condition A differed significantly from zero following the stimulus at time 0.25 s.\n",
    "\n",
    "Finally, we assessed whether the two ERPs from condition A and condition B differed. We did so through visual inspection, by comparing the differences in the ERPs, and by computing a statistic and assessing its significance through a bootstrapping procedure. Using the last procedure, we concluded that the ERP in the two conditions significantly differed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#introduction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
